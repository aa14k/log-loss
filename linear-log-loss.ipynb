{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b77b2b8-d788-492d-9df3-8d21e6196705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T22:31:47.956284Z",
     "iopub.status.busy": "2023-08-28T22:31:47.955822Z",
     "iopub.status.idle": "2023-08-28T22:31:47.960378Z",
     "shell.execute_reply": "2023-08-28T22:31:47.959504Z",
     "shell.execute_reply.started": "2023-08-28T22:31:47.956251Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2626cb78-10d0-401a-8991-cf8ced42c45b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T03:16:39.245445Z",
     "iopub.status.busy": "2023-08-26T03:16:39.244955Z",
     "iopub.status.idle": "2023-08-26T03:16:39.249123Z",
     "shell.execute_reply": "2023-08-26T03:16:39.248429Z",
     "shell.execute_reply.started": "2023-08-26T03:16:39.245412Z"
    },
    "tags": []
   },
   "source": [
    "# Linear Models with Logarithmic Loss\n",
    "\n",
    "Consider the following protocol: for $t=1,2,...,T$, nature chooses $x_t \\in \\mathbb{R}^d$ in each round, and then reveals a noisy label $y_t \\sim \\text{Ber}(x_t^\\top \\theta^\\star)$, where $\\theta^\\star \\in \\mathbb{R}^d$ is the unknown parameter. Our goal is to learn to make accurate predictions given a linear model class and any $x \\in \\mathbb{R}^d$, i.e., to predict $y^\\star(x) = x^\\top \\theta^\\star$. The classical way of learning $\\theta^\\star$ given i.i.d samples of $\\{x_t,y_t\\}_{t=1}^T$ is to perform ridge regression.\n",
    "\n",
    "Ridge regression considers the following estimator and prediction: given $\\{x_t,y_t\\}_{t=1}^T$ compute:\n",
    "\n",
    "$$\n",
    "\\hat\\theta_T := \\arg\\min_{\\theta \\in \\mathbb{R}^d} \\sum_{t=1}^T \\left( x_t^\\top \\theta - y_i\\right)^2 + \n",
    "\\lVert \\theta \\rVert^2\n",
    "$$\n",
    "\n",
    "and set $\\hat y_T(x) := x^\\top \\hat\\theta_T$. This is simply least-sqaures regression with $\\ell_2$ regularization. The estimator and the prediciton can also be solved in closed form. Define $V_t := I + \\sum_{t=1}^T x_t x_t^\\top$, then we have:\n",
    "\n",
    "$$\n",
    "\\hat y_T(x) = x^\\top V_t^{-1} \\sum_{t=1}^T x_t y_t.\n",
    "$$\n",
    "\n",
    "Another way of learning $\\theta^\\star$  given i.i.d samples of $\\{x_t,y_t\\}_{t=1}^T$ is to perform linear regression with the negative logarithmic (cross-entropy) loss. \n",
    "\n",
    "Linear regression with negative logarithmic loss considers the following estimator and prediciton: given $\\{x_t,y_t\\}_{t=1}^T$ compute:\n",
    "\n",
    "$$\n",
    "\\hat\\theta_T := \\arg\\max_{\\theta \\in \\mathbb{R}^d} \\mathcal{L}(\\{x_t,y_t\\}_{t=1}^T;\\theta) = \\arg\\max_{\\theta \\in \\mathbb{R}^d}  \\sum_{t=1}^T y_t \\log(x_t^\\top \\theta) + (1-y_t)\\log(1-x_t^\\top \\theta)\n",
    "$$\n",
    "and set $\\hat y_T(x) := x^\\top \\hat\\theta_T$. The estimaotr and the prediciton cannot be solved in closed form, however the loss function defined above is concave in its argument. Therefore approximate solvers like Newtown's method or Gradient Descent, should be sufficient for finding the $\\theta$ that minimizes the negative logarithmic loss. Taking the first derivative of the loss $\\mathcal{L}$ we get:2*\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta}  \\mathcal{L}(\\{x_t,y_t\\}_{t=1}^T;\\theta) = g_T(\\theta) :=  \\sum_{t=1}^T \\left(\\frac{y_t}{x_t^\\top \\theta} - \\frac{1-y_t}{1-x_t^\\top \\theta}\\right) x_t - 2\\theta.\n",
    "$$\n",
    "\n",
    "Taking the second derivative of $\\mathcal{L}$ gives:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2}{\\partial \\theta^2}  \\mathcal{L}(\\{x_t,y_t\\}_{t=1}^T;\\theta)= H_T(\\theta) :=  \\sum_{t=1}^T -\\left(\\frac{y_t}{(x_t^\\top\\theta)^2} + \\frac{1-y_t}{(1-x_t^\\top\\theta)^2}\\right) x_t x_t^\\top - I.\n",
    "$$\n",
    "\n",
    "Notice that we are trying to solve for the zeros of $g_T(\\theta)$. This function has three zeros at $\\theta = \\{-\\infty, \\arg\\max_{\\theta \\in \\mathbb{R}^d} \\mathcal{L}(\\{x_t,y_t\\}_{t=1}^T;\\theta), \\infty\\}$. Therefore, we need to constraint our optimization routine otherwise our estimate of $\\theta$ may diverge.\n",
    "\n",
    "One idea is to use Frank-Wolfe to ensure $\\theta$ does not diverge off to infinity. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Thus we can solve:\n",
    "\n",
    "$$\n",
    "\\hat\\theta_T := \\arg\\min_{\\theta \\in \\mathbb{R}^d} - \\mathcal{L}(\\{x_t,y_t\\}_{t=1}^T;\\theta)\n",
    "$$\n",
    "\n",
    "by applying Newton's method for $k=1,2,...,n$, i.e.\n",
    "\n",
    "$$\n",
    "\\theta_{k+1} = \\theta_k - \\left(H_T^{-1}(\\theta_k)\\right)^\\top g_t(\\theta_k).\n",
    "$$\n",
    "\n",
    "where $\\theta_0$ is initialized apprioately, i.e. $\\theta_0 \\sim \\mathcal{N}(0,I)$. Setting $\\hat\\theta_T = \\theta_n$ gives us our estimator and letting $\\hat y_T(x) = x^\\top \\hat\\theta_T$ gives us our predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a5337794-edde-42a5-aa65-bbd46f2ce180",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T22:31:48.561887Z",
     "iopub.status.busy": "2023-08-28T22:31:48.561468Z",
     "iopub.status.idle": "2023-08-28T22:31:48.930424Z",
     "shell.execute_reply": "2023-08-28T22:31:48.929445Z",
     "shell.execute_reply.started": "2023-08-28T22:31:48.561856Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = 2\n",
    "num_features = 4\n",
    "theta_star = np.random.uniform(size=d)\n",
    "theta_star = theta_star / (10*np.linalg.norm(theta_star))\n",
    "X = np.random.uniform(size=(num_features,d))\n",
    "for i in range(num_features):\n",
    "    X[i] = X[i] / np.linalg.norm(X[i])\n",
    "X[0] = X[0] / 1000\n",
    "X[1] = X[1] / 900\n",
    "X[2] = X[2] / 800\n",
    "X[3] = X[3] / 700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "798f87db-2ba0-4d13-8b6e-852ba7889312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T22:31:49.969438Z",
     "iopub.status.busy": "2023-08-28T22:31:49.969032Z",
     "iopub.status.idle": "2023-08-28T22:31:58.830748Z",
     "shell.execute_reply": "2023-08-28T22:31:58.829873Z",
     "shell.execute_reply.started": "2023-08-28T22:31:49.969408Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b946fb64f5401db77680a56ece83a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 1000**2\n",
    "features = np.zeros((num_samples,d))\n",
    "tar = np.zeros(num_samples)\n",
    "for i in tqdm(range(num_samples)):\n",
    "    j = i % num_features\n",
    "    feature = X[j]\n",
    "    mean = np.inner(X[j],theta_star)\n",
    "    obs = np.random.binomial(1,p=mean) - 1/2 \n",
    "    features[i] = feature\n",
    "    tar[i] = obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d7b7b3d-20ab-49b4-9c40-e4f0d58bbe62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T17:49:50.514545Z",
     "iopub.status.busy": "2023-08-28T17:49:50.514097Z",
     "iopub.status.idle": "2023-08-28T17:49:50.528127Z",
     "shell.execute_reply": "2023-08-28T17:49:50.527386Z",
     "shell.execute_reply.started": "2023-08-28T17:49:50.514516Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearLogRegression(object):\n",
    "    def __init__(self, features, obs, d, newton_iters,theta_star):\n",
    "        self.features = features\n",
    "        self.obs = obs\n",
    "        self.n = len(obs)\n",
    "        self.newton_iters = newton_iters\n",
    "        self.d = d\n",
    "        self.theta_star = theta_star\n",
    "        self.step_size = 1/self.newton_iters\n",
    "    \n",
    "    \n",
    "    def get_hessian_loss(self,theta):\n",
    "        H = np.zeros((self.d,self.d))\n",
    "        g = np.zeros(self.d)\n",
    "        for i in range(self.n):\n",
    "            y = self.obs[i]\n",
    "            x = self.features[i]\n",
    "            inner = np.inner(x,self.theta)\n",
    "            if inner == 1:\n",
    "                inner = 0.9999\n",
    "            elif inner == 0:\n",
    "                inner = 0.0001\n",
    "            if y == 0:\n",
    "                mu =   (1 - y) / ((1 - inner) ** 2)\n",
    "                H +=  -1.0 *mu * np.outer(x,x)\n",
    "\n",
    "                g += -1.0*( (1 - y) / ((1 - inner))) * x\n",
    "            else:\n",
    "                mu = y / (inner ** 2) \n",
    "                H +=  -1.0 * mu * np.outer(x,x)\n",
    "\n",
    "                g += (y / (inner) ) * x\n",
    "        return H, g\n",
    "    \n",
    "    def Newton_Method(self):\n",
    "        self.theta = np.zeros(self.d) + 0.3\n",
    "        for k in tqdm(range(self.newton_iters)):\n",
    "            H,g = self.get_hessian_loss(self.theta)\n",
    "            self.update = np.linalg.solve(H,g)\n",
    "            self.theta = self.theta - self.step_size/(k+1) * self.update\n",
    "            if k % 1000 == 999:\n",
    "                print('Log Loss', np.linalg.norm(self.theta - self.theta_star))\n",
    "            \n",
    "    \n",
    "    \n",
    "    def Least_Squares(self):\n",
    "        A = np.zeros((self.d,self.d))\n",
    "        b = np.zeros(self.d)\n",
    "        for i in range(self.n):\n",
    "            x = self.features[i]\n",
    "            y = self.obs[i]\n",
    "            A = A + np.outer(x,x)\n",
    "            b = b + y * x\n",
    "        self.theta_ls = np.linalg.solve(A,b)\n",
    "        print('Least Squares:' , np.linalg.norm(self.theta_ls - self.theta_star))\n",
    "    \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3df8e6be-ffc6-4055-91af-8b6cbc0ff584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T17:51:58.428369Z",
     "iopub.status.busy": "2023-08-28T17:51:58.427895Z",
     "iopub.status.idle": "2023-08-28T17:52:08.043410Z",
     "shell.execute_reply": "2023-08-28T17:52:08.042362Z",
     "shell.execute_reply.started": "2023-08-28T17:51:58.428338Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "Least Squares: 0.035672400657914376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092714171aa04442a7d4181f63710770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60044/3897832435.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearLogRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeast_Squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewton_Method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_60044/3283136698.py\u001b[0m in \u001b[0;36mNewton_Method\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewton_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hessian_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_60044/3283136698.py\u001b[0m in \u001b[0;36mget_hessian_loss\u001b[0;34m(self, theta)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mH\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_data = 50000\n",
    "print(np.dot(X,reg.theta_ls))\n",
    "reg = LinearLogRegression(features[:num_data],tar[:num_data],d,10000,theta_star)\n",
    "reg.Least_Squares()\n",
    "reg.Newton_Method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f3af9a61-b281-462c-8905-97efcd14d264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T17:52:25.731244Z",
     "iopub.status.busy": "2023-08-28T17:52:25.730757Z",
     "iopub.status.idle": "2023-08-28T17:52:25.737573Z",
     "shell.execute_reply": "2023-08-28T17:52:25.736706Z",
     "shell.execute_reply.started": "2023-08-28T17:52:25.731210Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.14543395e-05, 1.18307899e-04, 1.26959165e-04, 1.50817799e-04])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X,reg.theta_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee28359b-2f4e-4c4a-9fa9-fcf6f4e43426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T17:52:28.257494Z",
     "iopub.status.busy": "2023-08-28T17:52:28.257051Z",
     "iopub.status.idle": "2023-08-28T17:52:28.263639Z",
     "shell.execute_reply": "2023-08-28T17:52:28.262771Z",
     "shell.execute_reply.started": "2023-08-28T17:52:28.257463Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0003884 , 0.0004709 , 0.00052044, 0.00057639])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X,reg.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9544e402-a7c3-49f0-93be-e4d594d4750a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T17:52:50.763104Z",
     "iopub.status.busy": "2023-08-28T17:52:50.762604Z",
     "iopub.status.idle": "2023-08-28T17:52:50.769609Z",
     "shell.execute_reply": "2023-08-28T17:52:50.768715Z",
     "shell.execute_reply.started": "2023-08-28T17:52:50.763070Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.30950935e-05, 9.97654416e-05, 9.83755227e-05, 1.40936549e-04])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X,theta_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1324a8e-5171-4597-bced-4d5e62be8dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T17:12:30.696611Z",
     "iopub.status.busy": "2023-08-28T17:12:30.695361Z",
     "iopub.status.idle": "2023-08-28T17:12:30.702937Z",
     "shell.execute_reply": "2023-08-28T17:12:30.701959Z",
     "shell.execute_reply.started": "2023-08-28T17:12:30.696565Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95232579, 0.30508291])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "56842140-bdb8-4422-82c3-c4808dd905b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T20:46:31.432292Z",
     "iopub.status.busy": "2023-08-28T20:46:31.431837Z",
     "iopub.status.idle": "2023-08-28T20:46:31.438623Z",
     "shell.execute_reply": "2023-08-28T20:46:31.437681Z",
     "shell.execute_reply.started": "2023-08-28T20:46:31.432260Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.16656573e-06, 1.87761275e-06],\n",
       "       [1.87761275e-06, 4.67131850e-06]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X.T,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1d58a-91f2-4c7c-8949-b4bcc1713a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "nflx": {
   "sharing": {
    "created_at": "2023-08-26T03:11:28.333Z",
    "is_private": true
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
